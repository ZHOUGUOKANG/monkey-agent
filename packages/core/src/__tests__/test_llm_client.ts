/**
 * LLMClient æµ‹è¯•è„šæœ¬
 * 
 * æµ‹è¯•å†…å®¹ï¼š
 * 1. åŸºç¡€å¯¹è¯èƒ½åŠ› (chat)
 * 2. æµå¼å¯¹è¯èƒ½åŠ› (stream, streamText)
 * 3. Tool Calling (Function Calling)
 * 4. æ¨ç†èƒ½åŠ›é…ç½® (reasoning)
 * 5. å¤šæ¨¡å‹å…¼å®¹æ€§æµ‹è¯•
 * 6. è¾…åŠ©æ–¹æ³• (buildAssistantMessage, buildToolResultMessage)
 * 
 * æµ‹è¯•æ¨¡å‹ï¼š
 * - anthropic/claude-sonnet-4.5 (é»˜è®¤)
 * - google/gemini-2.5-pro
 * - google/gemini-2.5-flash
 * - openai/gpt-4.1
 * - openai/gpt-4.1-mini
 * - openai/gpt-5
 * 
 * ä½¿ç”¨è¯´æ˜ï¼š
 * 1. åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ï¼š
 *    OPENAI_API_KEY=your-key
 *    OPENAI_BASE_URL=your-litellm-url
 * 2. é»˜è®¤ä½¿ç”¨ anthropic/claude-sonnet-4.5
 * 3. é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šæ¨¡å‹ï¼šOPENAI_MODEL=google/gemini-2.5-pro yarn test:llm
 */

import { LLMClient } from '../llm/LLMClient';
import { initEnv, getLLMConfig, printEnvHelp } from '../utils/env-loader';
import { tool } from 'ai';
import { z } from 'zod';
import type { ModelMessage } from 'ai';

// ============================================
// ç¯å¢ƒåˆå§‹åŒ–
// ============================================

// åˆå§‹åŒ–ç¯å¢ƒå˜é‡
const validation = initEnv();
if (!validation.valid) {
  console.error(`âŒ ${validation.error}`);
  printEnvHelp();
  process.exit(1);
}

// è·å–é…ç½®ï¼ˆæ”¯æŒé€šè¿‡ OPENAI_MODEL ç¯å¢ƒå˜é‡è¦†ç›–æ¨¡å‹ï¼‰
const baseConfig = getLLMConfig();
const model = 'anthropic/claude-sonnet-4.5';

console.log('\nğŸ¤– LLMClient æµ‹è¯•');
console.log('='.repeat(60));
console.log(`ğŸ“¡ Base URL: ${baseConfig.baseURL || '(é»˜è®¤)'}`);
console.log(`ğŸ¯ æ¨¡å‹: ${model}`);
console.log('='.repeat(60));

// ============================================
// å·¥å…·å®šä¹‰
// ============================================

/**
 * å¤©æ°”æŸ¥è¯¢å·¥å…·
 */
const getWeatherTool = tool({
  description: 'æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯',
  inputSchema: z.object({
    city: z.string().describe('åŸå¸‚åç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·ã€çº½çº¦'),
    unit: z.enum(['celsius', 'fahrenheit']).optional().describe('æ¸©åº¦å•ä½'),
  }),
  // @ts-expect-error - Parameter type inference issue
  execute: async ({ city, unit = 'celsius' }) => {
    // æ¨¡æ‹Ÿ API è°ƒç”¨å»¶è¿Ÿ
    await new Promise(resolve => setTimeout(resolve, 500));
    
    // æ¨¡æ‹Ÿå¤©æ°”æ•°æ®
    const weatherData: Record<string, any> = {
      'åŒ—äº¬': { temp: 15, conditions: 'æ™´æœ—', humidity: 45 },
      'ä¸Šæµ·': { temp: 22, conditions: 'å¤šäº‘', humidity: 65 },
      'çº½çº¦': { temp: 18, conditions: 'é˜´å¤©', humidity: 55 },
      'New York': { temp: 18, conditions: 'Cloudy', humidity: 55 },
      'Paris': { temp: 16, conditions: 'Rainy', humidity: 70 },
      'å·´é»': { temp: 16, conditions: 'å°é›¨', humidity: 70 },
    };
    
    const data = weatherData[city] || { temp: 20, conditions: 'æœªçŸ¥', humidity: 50 };
    
    // è½¬æ¢æ¸©åº¦å•ä½
    if (unit === 'fahrenheit') {
      data.temp = Math.round(data.temp * 9 / 5 + 32);
    }
    
    return {
      city,
      temperature: data.temp,
      conditions: data.conditions,
      humidity: data.humidity,
      unit: unit as string,
    };
  },
} as any);

/**
 * è®¡ç®—å™¨å·¥å…·
 */
const calculatorTool = tool({
  description: 'æ‰§è¡Œæ•°å­¦è®¡ç®—',
  inputSchema: z.object({
    expression: z.string().describe('æ•°å­¦è¡¨è¾¾å¼ï¼Œä¾‹å¦‚ï¼š2 + 2, 10 * 5'),
  }),
  // @ts-expect-error - Parameter type inference issue
  execute: async ({ expression }) => {
    try {
      // ç®€å•çš„å®‰å…¨è®¡ç®—ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼‰
      const result = Function(`"use strict"; return (${expression})`)();
      return { expression, result };
    } catch (error) {
      return { expression, error: 'è®¡ç®—é”™è¯¯' };
    }
  },
} as any);

// ============================================
// æµ‹è¯•ç”¨ä¾‹
// ============================================

/**
 * æµ‹è¯• 1: åŸºç¡€å¯¹è¯
 */
async function testBasicChat(client: LLMClient, testName: string) {
  console.log(`\nğŸ“ [${testName}] æµ‹è¯• 1: åŸºç¡€å¯¹è¯`);
  console.log('-'.repeat(60));
  
  try {
    const messages: ModelMessage[] = [
      { role: 'user', content: 'ä½ å¥½ï¼è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚' },
    ];
    
    const result = await client.chat(messages);
    
    console.log(`âœ… å“åº”: ${result.text}`);
    console.log(`ğŸ“Š Token ä½¿ç”¨: ${result.usage.totalTokens}`);
    console.log(`ğŸ ç»“æŸåŸå› : ${result.finishReason}`);
    
    return true;
  } catch (error: any) {
    console.error(`âŒ å¤±è´¥: ${error.message}`);
    return false;
  }
}

/**
 * æµ‹è¯• 2: æµå¼å¯¹è¯ (ä½¿ç”¨ stream æ–¹æ³•)
 */
async function testStreamWithFullResult(client: LLMClient, testName: string) {
  console.log(`\nğŸŒŠ [${testName}] æµ‹è¯• 2: æµå¼å¯¹è¯ (stream æ–¹æ³•)`);
  console.log('-'.repeat(60));
  
  try {
    const messages: ModelMessage[] = [
      { role: 'user', content: 'ç”¨ä¸‰å¥è¯ä»‹ç» TypeScript çš„ä¼˜åŠ¿ã€‚' },
    ];
    
    const result = client.stream(messages);
    
    // ä½¿ç”¨ textStream
    process.stdout.write('ğŸ“¤ æµå¼è¾“å‡º: ');
    for await (const chunk of result.textStream) {
      process.stdout.write(chunk);
    }
    console.log('\n');
    
    // ç­‰å¾…å®Œæˆå¹¶è·å–ç»Ÿè®¡ä¿¡æ¯
    const usage = await result.usage;
    const finishReason = await result.finishReason;
    
    console.log(`ğŸ“Š Token ä½¿ç”¨: ${usage.totalTokens}`);
    console.log(`ğŸ ç»“æŸåŸå› : ${finishReason}`);
    
    return true;
  } catch (error: any) {
    console.error(`\nâŒ å¤±è´¥: ${error.message}`);
    return false;
  }
}

/**
 * æµ‹è¯• 3: æµå¼å¯¹è¯ (ä½¿ç”¨ streamText ä¾¿æ·æ–¹æ³•)
 */
async function testStreamText(client: LLMClient, testName: string) {
  console.log(`\nğŸŒŠ [${testName}] æµ‹è¯• 3: æµå¼å¯¹è¯ (streamText ä¾¿æ·æ–¹æ³•)`);
  console.log('-'.repeat(60));
  
  try {
    const messages: ModelMessage[] = [
      { role: 'user', content: 'åˆ—ä¸¾ä¸‰ä¸ªç¼–ç¨‹è¯­è¨€åŠå…¶ç‰¹ç‚¹ã€‚' },
    ];
    
    process.stdout.write('ğŸ“¤ æµå¼è¾“å‡º: ');
    for await (const chunk of client.streamText(messages)) {
      process.stdout.write(chunk);
    }
    console.log('\nâœ… å®Œæˆ');
    
    return true;
  } catch (error: any) {
    console.error(`\nâŒ å¤±è´¥: ${error.message}`);
    return false;
  }
}

/**
 * æµ‹è¯• 4: Tool Calling - å•ä¸ªå·¥å…·
 */
async function testSingleToolCall(client: LLMClient, testName: string) {
  console.log(`\nğŸ”§ [${testName}] æµ‹è¯• 4: Tool Calling - å•ä¸ªå·¥å…·`);
  console.log('-'.repeat(60));
  
  try {
    const messages: ModelMessage[] = [
      { role: 'user', content: 'åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ' },
    ];
    
    const result = await client.chat(messages, {
      tools: { getWeather: getWeatherTool },
      maxSteps: 5,
    });
    
    console.log(`âœ… å“åº”: ${result.text}`);
    console.log(`ğŸ“Š æ­¥éª¤æ•°: ${result.steps.length}`);
    
    // æ‰“å°å·¥å…·è°ƒç”¨è¯¦æƒ…
    result.steps.forEach((step, index) => {
      if (step.toolCalls && step.toolCalls.length > 0) {
        console.log(`\nğŸ”§ æ­¥éª¤ ${index + 1} - å·¥å…·è°ƒç”¨:`);
        step.toolCalls.forEach(tc => {
          console.log(`  - ${tc.toolName}(${JSON.stringify((tc as any).args || (tc as any).input)})`);
        });
      }
      if (step.toolResults && step.toolResults.length > 0) {
        console.log(`ğŸ“‹ æ­¥éª¤ ${index + 1} - å·¥å…·ç»“æœ:`);
        step.toolResults.forEach(tr => {
          console.log(`  - ${tr.toolName}: ${JSON.stringify((tr as any).result || (tr as any).output)}`);
        });
      }
    });
    
    return true;
  } catch (error: any) {
    console.error(`âŒ å¤±è´¥: ${error.message}`);
    return false;
  }
}

/**
 * æµ‹è¯• 5: Tool Calling - å¤šä¸ªå·¥å…·å¹¶è¡Œ
 */
async function testMultipleToolCalls(client: LLMClient, testName: string) {
  console.log(`\nğŸ”§ [${testName}] æµ‹è¯• 5: Tool Calling - å¤šä¸ªå·¥å…·å¹¶è¡Œ`);
  console.log('-'.repeat(60));
  
  try {
    const messages: ModelMessage[] = [
      { role: 'user', content: 'è¯·å‘Šè¯‰æˆ‘åŒ—äº¬å’Œä¸Šæµ·çš„å¤©æ°”ï¼Œç„¶åè®¡ç®—å®ƒä»¬çš„å¹³å‡æ¸©åº¦ã€‚' },
    ];
    
    const result = await client.chat(messages, {
      tools: { 
        getWeather: getWeatherTool,
        calculator: calculatorTool,
      },
      maxSteps: 10,
    });
    
    console.log(`âœ… å“åº”: ${result.text}`);
    console.log(`ğŸ“Š æ­¥éª¤æ•°: ${result.steps.length}`);
    
    // ç»Ÿè®¡å·¥å…·è°ƒç”¨
    let toolCallCount = 0;
    result.steps.forEach((step, index) => {
      if (step.toolCalls && step.toolCalls.length > 0) {
        toolCallCount += step.toolCalls.length;
        console.log(`\nğŸ”§ æ­¥éª¤ ${index + 1} - ${step.toolCalls.length} ä¸ªå·¥å…·è°ƒç”¨:`);
        step.toolCalls.forEach(tc => {
          console.log(`  - ${tc.toolName}: ${JSON.stringify((tc as any).args || (tc as any).input)}`);
        });
      }
    });
    
    console.log(`\nğŸ”¢ æ€»å·¥å…·è°ƒç”¨æ¬¡æ•°: ${toolCallCount}`);
    
    return true;
  } catch (error: any) {
    console.error(`âŒ å¤±è´¥: ${error.message}`);
    return false;
  }
}

/**
 * æµ‹è¯• 6: Tool Calling - æµå¼ + å·¥å…·è°ƒç”¨
 */
async function testStreamWithTools(client: LLMClient, testName: string) {
  console.log(`\nğŸŒŠ [${testName}] æµ‹è¯• 6: æµå¼ + å·¥å…·è°ƒç”¨`);
  console.log('-'.repeat(60));
  
  try {
    const messages: ModelMessage[] = [
      { role: 'user', content: 'æŸ¥è¯¢å·´é»çš„å¤©æ°”ï¼Œå¹¶ç”¨åæ°åº¦å‘Šè¯‰æˆ‘æ¸©åº¦ã€‚' },
    ];
    
    const result = client.stream(messages, {
      tools: { getWeather: getWeatherTool },
      maxSteps: 5,
    });
    
    // ç›‘å¬å®Œæ•´äº‹ä»¶æµ
    console.log('ğŸ“¤ äº‹ä»¶æµ:');
    for await (const event of result.fullStream) {
      switch (event.type) {
        case 'text-delta':
          process.stdout.write((event as any).textDelta || (event as any).text || '');
          break;
        case 'tool-call':
          console.log(`\nğŸ”§ å·¥å…·è°ƒç”¨: ${(event as any).toolName}(${JSON.stringify((event as any).args || (event as any).input)})`);
          break;
        case 'tool-result':
          console.log(`ğŸ“‹ å·¥å…·ç»“æœ: ${JSON.stringify((event as any).result || (event as any).output)}`);
          break;
        case 'finish':
          console.log(`\nğŸ å®Œæˆ: ${(event as any).finishReason}`);
          break;
      }
    }
    
    const finalText = await result.text;
    console.log(`\nâœ… æœ€ç»ˆæ–‡æœ¬: ${finalText}`);
    
    return true;
  } catch (error: any) {
    console.error(`\nâŒ å¤±è´¥: ${error.message}`);
    return false;
  }
}

/**
 * æµ‹è¯• 7: è¾…åŠ©æ–¹æ³• - buildAssistantMessage & buildToolResultMessage
 */
async function testHelperMethods(client: LLMClient, testName: string) {
  console.log(`\nğŸ› ï¸  [${testName}] æµ‹è¯• 7: è¾…åŠ©æ–¹æ³•`);
  console.log('-'.repeat(60));
  
  try {
    // ç¬¬ä¸€è½®ï¼šè§¦å‘å·¥å…·è°ƒç”¨
    const messages: ModelMessage[] = [
      { role: 'user', content: 'çº½çº¦ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ' },
    ];
    
    const result1 = await client.chat(messages, {
      tools: { getWeather: getWeatherTool },
      maxSteps: 1, // åªæ‰§è¡Œä¸€æ­¥ï¼Œä¸è‡ªåŠ¨ç»§ç»­
    });
    
    if (!result1.toolCalls || result1.toolCalls.length === 0) {
      console.log('âš ï¸  æœªè§¦å‘å·¥å…·è°ƒç”¨ï¼Œè·³è¿‡æµ‹è¯•');
      return true;
    }
    
    console.log('âœ… ç¬¬ä¸€è½®å®Œæˆï¼Œè§¦å‘äº†å·¥å…·è°ƒç”¨');
    
    // æ‰‹åŠ¨æ‰§è¡Œå·¥å…·
    const toolCall = result1.toolCalls[0];
    const toolCallArgs = (toolCall as any).args || (toolCall as any).input;
    console.log(`ğŸ”§ æ‰‹åŠ¨æ‰§è¡Œå·¥å…·: ${toolCall.toolName}(${JSON.stringify(toolCallArgs)})`);
    
    const toolResult = await (getWeatherTool as any).execute(toolCallArgs, {} as any);
    console.log(`ğŸ“‹ å·¥å…·ç»“æœ: ${JSON.stringify(toolResult)}`);
    
    // ä½¿ç”¨è¾…åŠ©æ–¹æ³•æ„å»ºæ¶ˆæ¯
    const assistantMessage = client.buildAssistantMessage([{
      toolCallId: toolCall.toolCallId,
      toolName: toolCall.toolName,
      input: toolCallArgs,
    }]);
    
    const toolResultMessage = client.buildToolResultMessage(
      { toolCallId: toolCall.toolCallId, toolName: toolCall.toolName },
      toolResult
    );
    
    // ç¬¬äºŒè½®ï¼šç»§ç»­å¯¹è¯ï¼ˆéœ€è¦ä¼ é€’ tools å‚æ•°ï¼ŒæŸäº›æ¨¡å‹å¦‚ Anthropic è¦æ±‚ï¼‰
    const messages2: ModelMessage[] = [
      ...messages,
      assistantMessage,
      toolResultMessage,
    ];
    
    const result2 = await client.chat(messages2, {
      tools: { getWeather: getWeatherTool },
    });
    
    console.log(`âœ… ç¬¬äºŒè½®å“åº”: ${result2.text}`);
    console.log('âœ… è¾…åŠ©æ–¹æ³•æµ‹è¯•é€šè¿‡');
    
    return true;
  } catch (error: any) {
    console.error(`âŒ å¤±è´¥: ${error.message}`);
    return false;
  }
}

/**
 * æµ‹è¯• 8: ç³»ç»Ÿæç¤ºè¯
 */
async function testSystemPrompt(client: LLMClient, testName: string) {
  console.log(`\nğŸ“‹ [${testName}] æµ‹è¯• 8: ç³»ç»Ÿæç¤ºè¯`);
  console.log('-'.repeat(60));
  
  try {
    const messages: ModelMessage[] = [
      { role: 'user', content: 'ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±' },
    ];
    
    const result = await client.chat(messages, {
      system: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤©æ°”æ’­æŠ¥å‘˜ï¼Œæ€»æ˜¯ç”¨è¯—æ„çš„è¯­è¨€æè¿°å¤©æ°”ã€‚',
    });
    
    console.log(`âœ… å“åº”: ${result.text}`);
    
    return true;
  } catch (error: any) {
    console.error(`âŒ å¤±è´¥: ${error.message}`);
    return false;
  }
}

/**
 * æµ‹è¯• 9: é”™è¯¯å¤„ç†
 */
async function testErrorHandling(client: LLMClient, testName: string) {
  console.log(`\nâš ï¸  [${testName}] æµ‹è¯• 9: é”™è¯¯å¤„ç†`);
  console.log('-'.repeat(60));
  
  try {
    // æµ‹è¯•å·¥å…·æ‰§è¡Œé”™è¯¯
    const errorTool = tool({
      description: 'ä¸€ä¸ªä¼šæŠ›å‡ºé”™è¯¯çš„å·¥å…·',
      inputSchema: z.object({
        trigger: z.boolean(),
      }),
      // @ts-expect-error - Parameter type inference issue
      execute: async ({ trigger }) => {
        if (trigger) {
          throw new Error('æ•…æ„è§¦å‘çš„é”™è¯¯');
        }
        return { success: true };
      },
    } as any);
    
    const messages: ModelMessage[] = [
      { role: 'user', content: 'è¯·è°ƒç”¨ error å·¥å…·ï¼Œå‚æ•° trigger è®¾ä¸º true' },
    ];
    
    const result = await client.chat(messages, {
      tools: { error: errorTool },
      maxSteps: 3,
    });
    
    // AI SDK ä¸ä¼šå‘ä¸ŠæŠ›å‡ºå·¥å…·æ‰§è¡Œé”™è¯¯ï¼Œè€Œæ˜¯å°†é”™è¯¯åŒ…å«åœ¨ content ä¸­
    // æ£€æŸ¥æ˜¯å¦åŒ…å« tool-error ç±»å‹
    const hasToolError = result.content?.some((c: any) => c.type === 'tool-error');
    
    if (hasToolError) {
      const toolError = result.content?.find((c: any) => c.type === 'tool-error') as any;
      console.log(`âœ… å·¥å…·é”™è¯¯å·²è¢«æ•è·: ${toolError.toolName}`);
      console.log(`   é”™è¯¯ä¿¡æ¯: ${JSON.stringify(toolError.error)}`);
      return true;
    } else {
      console.log('âš ï¸  é¢„æœŸåº”è¯¥åŒ…å«å·¥å…·é”™è¯¯ï¼Œä½†æ²¡æœ‰æ‰¾åˆ°');
      return false;
    }
  } catch (error: any) {
    console.error(`âŒ æµ‹è¯•å¤±è´¥: ${error.message}`);
    return false;
  }
}

/**
 * æµ‹è¯• 10: å¤šè½®å¯¹è¯
 */
async function testMultiTurnConversation(client: LLMClient, testName: string) {
  console.log(`\nğŸ’¬ [${testName}] æµ‹è¯• 10: å¤šè½®å¯¹è¯`);
  console.log('-'.repeat(60));
  
  try {
    // ç¬¬ä¸€è½®
    let messages: ModelMessage[] = [
      { role: 'user', content: 'æˆ‘æƒ³äº†è§£åŒ—äº¬çš„å¤©æ°”' },
    ];
    
    const result1 = await client.chat(messages, {
      tools: { getWeather: getWeatherTool },
      maxSteps: 5,
    });
    
    console.log(`ğŸ¤– ç¬¬ä¸€è½®: ${result1.text}`);
    
    // æ·»åŠ åŠ©æ‰‹å“åº”åˆ°å†å²
    messages.push({ role: 'assistant', content: result1.text });
    
    // ç¬¬äºŒè½®
    messages.push({ role: 'user', content: 'é‚£ä¸Šæµ·å‘¢ï¼Ÿ' });
    
    const result2 = await client.chat(messages, {
      tools: { getWeather: getWeatherTool },
      maxSteps: 5,
    });
    
    console.log(`ğŸ¤– ç¬¬äºŒè½®: ${result2.text}`);
    
    // ç¬¬ä¸‰è½®
    messages.push({ role: 'assistant', content: result2.text });
    messages.push({ role: 'user', content: 'æ¯”è¾ƒä¸€ä¸‹è¿™ä¸¤ä¸ªåŸå¸‚çš„æ¸©åº¦' });
    
    const result3 = await client.chat(messages);
    
    console.log(`ğŸ¤– ç¬¬ä¸‰è½®: ${result3.text}`);
    console.log('âœ… å¤šè½®å¯¹è¯æµ‹è¯•é€šè¿‡');
    
    return true;
  } catch (error: any) {
    console.error(`âŒ å¤±è´¥: ${error.message}`);
    return false;
  }
}

// ============================================
// ä¸»æµ‹è¯•å‡½æ•°
// ============================================

/**
 * è¿è¡Œæ‰€æœ‰æµ‹è¯•
 */
async function runAllTests(model: string) {
  const testName = model.replace(/\//g, '-');
  
  console.log(`\n\n${'='.repeat(60)}`);
  console.log(`ğŸ§ª å¼€å§‹æµ‹è¯•æ¨¡å‹: ${model}`);
  console.log('='.repeat(60));
  
  // åˆ›å»º LLM å®¢æˆ·ç«¯
  const client = new LLMClient({
    ...baseConfig,
    model,
    // temperature: 0.7,
    maxTokens: 2000,
  });
  
  const tests = [
    { name: 'åŸºç¡€å¯¹è¯', fn: testBasicChat },
    { name: 'æµå¼å¯¹è¯ (stream)', fn: testStreamWithFullResult },
    { name: 'æµå¼å¯¹è¯ (streamText)', fn: testStreamText },
    { name: 'Tool Calling - å•ä¸ªå·¥å…·', fn: testSingleToolCall },
    { name: 'Tool Calling - å¤šä¸ªå·¥å…·', fn: testMultipleToolCalls },
    { name: 'æµå¼ + å·¥å…·è°ƒç”¨', fn: testStreamWithTools },
    { name: 'è¾…åŠ©æ–¹æ³•', fn: testHelperMethods },
    { name: 'ç³»ç»Ÿæç¤ºè¯', fn: testSystemPrompt },
    { name: 'é”™è¯¯å¤„ç†', fn: testErrorHandling },
    { name: 'å¤šè½®å¯¹è¯', fn: testMultiTurnConversation },
  ];
  
  const results: { name: string; success: boolean }[] = [];
  
  for (const test of tests) {
    try {
      const success = await test.fn(client, testName);
      results.push({ name: test.name, success });
      
      // æµ‹è¯•ä¹‹é—´çš„å»¶è¿Ÿï¼Œé¿å… API é™æµ
      await new Promise(resolve => setTimeout(resolve, 1000));
    } catch (error: any) {
      console.error(`\nâŒ æµ‹è¯• "${test.name}" å¼‚å¸¸: ${error.message}`);
      results.push({ name: test.name, success: false });
    }
  }
  
  // æ‰“å°æ±‡æ€»
  console.log(`\n\n${'='.repeat(60)}`);
  console.log(`ğŸ“Š ${model} æµ‹è¯•ç»“æœæ±‡æ€»`);
  console.log('='.repeat(60));
  
  const passed = results.filter(r => r.success).length;
  const failed = results.filter(r => !r.success).length;
  
  results.forEach(r => {
    const icon = r.success ? 'âœ…' : 'âŒ';
    console.log(`${icon} ${r.name}`);
  });
  
  console.log('-'.repeat(60));
  console.log(`é€šè¿‡: ${passed}/${results.length} | å¤±è´¥: ${failed}/${results.length}`);
  console.log('='.repeat(60));
  
  return { passed, failed, total: results.length };
}

// ============================================
// å¿«é€Ÿæµ‹è¯•æ¨¡å¼
// ============================================

/**
 * å¿«é€Ÿæµ‹è¯•ï¼ˆä»…åŸºç¡€åŠŸèƒ½ï¼‰
 */
async function runQuickTests(model: string) {
  const testName = model.replace(/\//g, '-');
  
  console.log(`\n\n${'='.repeat(60)}`);
  console.log(`âš¡ å¿«é€Ÿæµ‹è¯•æ¨¡å‹: ${model}`);
  console.log('='.repeat(60));
  
  const client = new LLMClient({
    ...baseConfig,
    model,
    temperature: 0.7,
    maxTokens: 1000,
  });
  
  const tests = [
    { name: 'åŸºç¡€å¯¹è¯', fn: testBasicChat },
    { name: 'Tool Calling', fn: testSingleToolCall },
    { name: 'æµå¼å¯¹è¯', fn: testStreamText },
  ];
  
  const results: { name: string; success: boolean }[] = [];
  
  for (const test of tests) {
    try {
      const success = await test.fn(client, testName);
      results.push({ name: test.name, success });
      await new Promise(resolve => setTimeout(resolve, 500));
    } catch (error: any) {
      console.error(`\nâŒ æµ‹è¯• "${test.name}" å¼‚å¸¸: ${error.message}`);
      results.push({ name: test.name, success: false });
    }
  }
  
  const passed = results.filter(r => r.success).length;
  console.log(`\nâœ… ${model}: ${passed}/${results.length} é€šè¿‡`);
  
  return { passed, failed: results.length - passed, total: results.length };
}

// ============================================
// ç¨‹åºå…¥å£
// ============================================

async function main() {
  const args = process.argv.slice(2);
  const mode = args[0] || 'single'; // single | quick | all
  
  try {
    if (mode === 'all') {
      // æµ‹è¯•æ‰€æœ‰æ¨¡å‹ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰
      console.log('\nğŸš€ æ‰¹é‡æµ‹è¯•æ¨¡å¼ï¼ˆå¿«é€Ÿï¼‰');
      
      const models = [
        'anthropic/claude-sonnet-4.5',
        'google/gemini-2.5-pro',
        'google/gemini-2.5-flash',
        'openai/gpt-4.1',
        'openai/gpt-4.1-mini',
        'openai/gpt-5',
      ];
      
      const allResults = [];
      
      for (const model of models) {
        try {
          const result = await runQuickTests(model);
          allResults.push({ model, ...result });
        } catch (error: any) {
          console.error(`\nâŒ ${model} æµ‹è¯•å¤±è´¥: ${error.message}\n`);
          allResults.push({ model, passed: 0, failed: 3, total: 3 });
        }
        
        // æ¨¡å‹ä¹‹é—´çš„å»¶è¿Ÿ
        await new Promise(resolve => setTimeout(resolve, 2000));
      }
      
      // æ‰“å°æ€»æ±‡æ€»
      console.log(`\n\n${'='.repeat(60)}`);
      console.log('ğŸ“Š æ‰€æœ‰æ¨¡å‹æµ‹è¯•æ±‡æ€»');
      console.log('='.repeat(60));
      
      allResults.forEach(r => {
        const status = r.failed === 0 ? 'âœ…' : r.passed > 0 ? 'âš ï¸' : 'âŒ';
        console.log(`${status} ${r.model}: ${r.passed}/${r.total} é€šè¿‡`);
      });
      
      console.log('='.repeat(60));
      
    } else if (mode === 'quick') {
      // å¿«é€Ÿæµ‹è¯•å½“å‰æ¨¡å‹
      await runQuickTests(model);
    } else {
      // å®Œæ•´æµ‹è¯•å½“å‰æ¨¡å‹
      await runAllTests(model);
    }
    
    console.log('\nâœ… æµ‹è¯•å®Œæˆï¼\n');
    
  } catch (error: any) {
    console.error(`\nâŒ æµ‹è¯•å¤±è´¥: ${error.message}`);
    console.error(error.stack);
    process.exit(1);
  }
}

// è¿è¡Œæµ‹è¯•
main();
