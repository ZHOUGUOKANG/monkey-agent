# @monkey-agent/core

Monkey Agent æ ¸å¿ƒæ¡†æ¶ï¼Œæä¾› LLM é›†æˆã€ReAct Agent åŸºç±»ã€ä¸Šä¸‹æ–‡å‹ç¼©å’Œè·¨ç¯å¢ƒæ”¯æŒã€‚

## ç‰¹æ€§

- ğŸ§  **LLM Client** - åŸºäº [Vercel AI SDK](https://sdk.vercel.ai)ï¼Œæ”¯æŒ OpenAI/Anthropic/Google ç­‰
- ğŸ”„ **ReAct Agent** - å†…ç½®"æ¨ç† â†’ è¡ŒåŠ¨ â†’ è§‚å¯Ÿ"å¾ªç¯çš„ BaseAgent åŸºç±»
- ğŸ› ï¸ **Tool Calling** - å®Œæ•´çš„å·¥å…·è°ƒç”¨æ”¯æŒï¼Œè‡ªåŠ¨æ‰§è¡Œæˆ–æ‰‹åŠ¨æ§åˆ¶
- ğŸ’¬ **ä¸Šä¸‹æ–‡å‹ç¼©** - æ··åˆç­–ç•¥æ™ºèƒ½å‹ç¼©ï¼Œè§£å†³é•¿å¯¹è¯ token é™åˆ¶
- ğŸŒ **è·¨ç¯å¢ƒ** - ç»Ÿä¸€ API æ”¯æŒ Node.js å’Œæµè§ˆå™¨
- ğŸ’­ **æ¨ç†é…ç½®** - æ”¯æŒ Claude Extended Thinkingã€OpenAI o1 ç­‰

## å®‰è£…

```bash
yarn add @monkey-agent/core
```

## å¿«é€Ÿå¼€å§‹

### 1. LLM Client

```typescript
import { LLMClient } from '@monkey-agent/core';

const client = new LLMClient({
  provider: 'openai',
  apiKey: process.env.OPENAI_API_KEY,
  model: 'gpt-4',
});

// å¯¹è¯
const result = await client.chat([
  { role: 'user', content: 'ä½ å¥½ï¼' }
]);
console.log(result.text);

// æµå¼
for await (const chunk of client.streamText(messages)) {
  process.stdout.write(chunk);
}
```

### 2. Tool Calling

```typescript
import { tool, z } from 'ai';

const weatherTool = tool({
  description: 'æŸ¥è¯¢å¤©æ°”',
  inputSchema: z.object({ city: z.string() }),
  execute: async ({ city }) => {
    return { city, temperature: 15, conditions: 'æ™´' };
  },
});

const result = await client.chat(
  [{ role: 'user', content: 'åŒ—äº¬å¤©æ°”?' }],
  { tools: { getWeather: weatherTool }, maxSteps: 5 }
);

console.log(result.text);         // "åŒ—äº¬ä»Šå¤©æ™´ï¼Œ15Â°C"
console.log(result.steps.length); // 2 (å·¥å…·è°ƒç”¨ + æœ€ç»ˆå›ç­”)
```

### 3. åˆ›å»ºè‡ªå®šä¹‰ Agent

```typescript
import { BaseAgent } from '@monkey-agent/core';
import { tool, z } from 'ai';

class WeatherAgent extends BaseAgent {
  constructor() {
    super({
      id: 'weather-agent',
      name: 'Weather Assistant',
      description: 'æ™ºèƒ½å¤©æ°”åŠ©æ‰‹',
      capabilities: ['æŸ¥è¯¢å¤©æ°”'],
      llmConfig: {
        provider: 'openai',
        apiKey: process.env.OPENAI_API_KEY,
        model: 'gpt-4',
      },
    });
  }

  // å®šä¹‰å·¥å…·ï¼ˆä¸å« executeï¼‰
  protected getToolDefinitions() {
    return {
      getWeather: tool({
        description: 'æŸ¥è¯¢åŸå¸‚å¤©æ°”',
        inputSchema: z.object({
          city: z.string(),
        }),
      }),
    };
  }

  // æ‰‹åŠ¨å¤„ç†å·¥å…·æ‰§è¡Œ
  protected async executeToolCall(toolName: string, input: any) {
    if (toolName === 'getWeather') {
      // Agent å®Œå…¨æ§åˆ¶æ‰§è¡Œæµç¨‹
      return { city: input.city, temperature: 15 };
    }
    throw new Error(`æœªçŸ¥å·¥å…·: ${toolName}`);
  }
}

// ä½¿ç”¨
const agent = new WeatherAgent();

agent.on('react:action', ({ action, input }) => {
  console.log(`æ‰§è¡Œ: ${action}`, input);
});

const result = await agent.execute({
  id: 'task-1',
  type: 'query',
  description: 'åŒ—äº¬å’Œä¸Šæµ·å“ªä¸ªæ›´çƒ­ï¼Ÿ',
  parameters: {},
});

console.log(result.data.answer); // Agent çš„æœ€ç»ˆå›ç­”
console.log(result.data.steps);  // ReAct æ­¥éª¤è¯¦æƒ…
```

### 4. ä¸Šä¸‹æ–‡å‹ç¼©

```typescript
const agent = new WeatherAgent({
  // ...
  contextCompression: {
    enabled: true,
    maxMessages: 20,        // æ¶ˆæ¯æ•°é˜ˆå€¼
    maxTokens: 8000,        // Token æ•°é˜ˆå€¼
    keepRecentRounds: 3,    // å¤šè½®å¯¹è¯ï¼šä¿ç•™ 3 è½®
    keepRecentMessages: 10, // å•è½®å¤šå·¥å…·ï¼šä¿ç•™ 10 æ¡æ¶ˆæ¯
    autoRetryOnLength: true,
  },
});

// ç›‘å¬å‹ç¼©äº‹ä»¶
agent.on('context:compressed', ({ summary, newHistoryLength }) => {
  console.log('å·²å‹ç¼©:', summary);
});

// æ··åˆç­–ç•¥è‡ªåŠ¨é€‰æ‹©ï¼š
// - å¤šè½®å¯¹è¯ (â‰¥5è½®) â†’ åŸºäºè½®æ¬¡
// - å•è½®å¤šå·¥å…· (1è½®) â†’ åŸºäºæ¶ˆæ¯æ•°
// - è¾¹ç•Œæƒ…å†µ (2-4è½®) â†’ æ™ºèƒ½é€‰æ‹©
```

### 5. æ¨ç†èƒ½åŠ›é…ç½®

```typescript
// Claude Extended Thinking
const client = new LLMClient({
  provider: 'anthropic',
  model: 'claude-sonnet-4.5',
  reasoning: {
    thinking: true, // æˆ–è®¾ç½® token é¢„ç®—: thinking: 10000
  },
});

// OpenAI o1
const o1Client = new LLMClient({
  provider: 'openai',
  model: 'o1-preview',
  reasoning: {
    effort: 'high', // 'low' | 'medium' | 'high'
  },
});
```

## API å‚è€ƒ

### LLMClient

```typescript
// æ„é€ å‡½æ•°
new LLMClient(config: {
  provider?: 'openai' | 'anthropic' | 'google' | ...;
  apiKey?: string;
  model?: string;
  temperature?: number;
  maxTokens?: number;
  reasoning?: ReasoningConfig;
})

// æ–¹æ³•
client.chat(messages, options?)          // æ™®é€šå¯¹è¯
client.stream(messages, options?)        // æµå¼å¯¹è¯ï¼ˆè¿”å› StreamTextResultï¼‰
client.streamText(messages, options?)    // ä¾¿æ·æµå¼ï¼ˆç›´æ¥è¿­ä»£æ–‡æœ¬ï¼‰
client.buildAssistantMessage(toolCalls, text?) // æ„å»ºåŠ©æ‰‹æ¶ˆæ¯
client.buildToolResultMessage(toolCall, result) // æ„å»ºå·¥å…·ç»“æœ
```

### BaseAgent

```typescript
// æ„é€ å‡½æ•°
new BaseAgent(config: {
  id: string;
  name: string;
  description: string;
  capabilities: string[];
  llmConfig: LLMConfig;
  maxIterations?: number;      // é»˜è®¤ 25
  contextCompression?: { ... };
})

// æŠ½è±¡æ–¹æ³•ï¼ˆå­ç±»å®ç°ï¼‰
protected abstract getToolDefinitions(): ToolSet;
protected abstract executeToolCall(toolName: string, input: any): Promise<any>;

// ä¸»è¦æ–¹æ³•
agent.execute(task): Promise<TaskResult>  // æ‰§è¡Œä»»åŠ¡ï¼ˆReAct å¾ªç¯ï¼‰
agent.plan(goal): Promise<Plan>           // è§„åˆ’ä»»åŠ¡
agent.reflect(result): Promise<Reflection> // åæ€

// å·¥å…·æ–¹æ³•
agent.getConversationHistory()
agent.clearConversationHistory()
agent.getLLMClient()
agent.getCompressionSummary()
```

### äº‹ä»¶ç³»ç»Ÿ

```typescript
// ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸ
agent.on('task:start', (task) => {})
agent.on('task:complete', (result) => {})

// ReAct å¾ªç¯
agent.on('react:iteration', ({ iteration }) => {})
agent.on('react:action', ({ action, input }) => {})
agent.on('react:observation', ({ action, result }) => {})
agent.on('react:final-answer', ({ answer }) => {})

// ä¸Šä¸‹æ–‡å‹ç¼©
agent.on('context:compressed', ({ summary, newHistoryLength }) => {})
agent.on('context:proactive-compression-triggered', ({ messageCount }) => {})
agent.on('context:length-error-detected', ({ error }) => {})
```

## ç±»å‹å®šä¹‰

```typescript
import type {
  LLMConfig,
  LLMCallOptions,
  ReasoningConfig,
  IAgent,
  Task,
  TaskResult,
  Goal,
  Plan,
  Reflection,
  ToolSet,
  ModelMessage,
} from '@monkey-agent/core';
```

## ç¯å¢ƒå˜é‡

```bash
# .env æ–‡ä»¶
OPENAI_API_KEY=sk-...
OPENAI_BASE_URL=https://api.openai.com/v1  # å¯é€‰

ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_API_KEY=...
```

ä½¿ç”¨ç¯å¢ƒå·¥å…·å‡½æ•°ï¼š

```typescript
import { initEnv, getLLMConfig } from '@monkey-agent/core';

initEnv();  // åŠ è½½å¹¶éªŒè¯ç¯å¢ƒå˜é‡
const config = getLLMConfig('openai'); // è‡ªåŠ¨è¯»å–é…ç½®
const client = new LLMClient(config);
```

## æµ‹è¯•

```bash
yarn test:llm           # LLM Client æµ‹è¯•
yarn test:weather-agent # Weather Agent ç¤ºä¾‹
yarn test:compression   # ä¸Šä¸‹æ–‡å‹ç¼©æµ‹è¯•

# æŒ‡å®šæ¨¡å‹
OPENAI_MODEL=gpt-4 yarn test:llm
```

## æ¶æ„è®¾è®¡

```
BaseAgent (ReAct å¾ªç¯æ§åˆ¶)
    â†“
LLMClient (LLM é€šä¿¡)
    â†“
Vercel AI SDK (å¤šæä¾›å•†æ”¯æŒ)
```

**è®¾è®¡åŸåˆ™ï¼š**
- LLM Client ä¸“æ³¨äºé€šä¿¡ï¼Œä¸æ‰§è¡Œå·¥å…·
- BaseAgent æ§åˆ¶å·¥å…·æ‰§è¡Œæµç¨‹
- å·¥å…·å®šä¹‰ä¸æ‰§è¡Œåˆ†ç¦»ï¼ˆæ–¹ä¾¿é›†æˆ MCPï¼‰

## ä¾èµ–

- [Vercel AI SDK](https://sdk.vercel.ai) - ç»Ÿä¸€ AI SDK
- [@ai-sdk/openai](https://www.npmjs.com/package/@ai-sdk/openai) - OpenAI
- [@ai-sdk/anthropic](https://www.npmjs.com/package/@ai-sdk/anthropic) - Anthropic
- [@ai-sdk/google](https://www.npmjs.com/package/@ai-sdk/google) - Google
- [EventEmitter3](https://github.com/primus/eventemitter3) - äº‹ä»¶ç³»ç»Ÿ
- [Zod](https://zod.dev) - ç±»å‹éªŒè¯

## è¯¦ç»†æ–‡æ¡£

- [LLM Tool Calling](./src/llm/README.md) - å·¥å…·è°ƒç”¨è¯¦ç»†æŒ‡å—
- [ä¸Šä¸‹æ–‡å‹ç¼©](./src/compression/README.md) - å‹ç¼©ç­–ç•¥è¯¦è§£
- [å·¥å…·å‡½æ•°](./src/utils/README.md) - ç¯å¢ƒé…ç½®å·¥å…·

## è®¸å¯è¯

MIT
