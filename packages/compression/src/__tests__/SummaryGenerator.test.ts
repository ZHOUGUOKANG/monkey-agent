/**
 * SummaryGenerator å•å…ƒæµ‹è¯•
 */

import { describe, it, expect, beforeEach, vi } from 'vitest';
import { SummaryGenerator, summarizeMessages } from '../SummaryGenerator';
import type { ILLMClient } from '@monkey-agent/types';
import type { ModelMessage } from 'ai';

// æ¨¡æ‹Ÿ LLM å®¢æˆ·ç«¯
const createMockLLMClient = (mockResponse: string = 'Test summary'): ILLMClient => {
  return {
    chat: vi.fn().mockResolvedValue({ text: mockResponse }),
    stream: vi.fn(),
  } as any;
};

describe('SummaryGenerator', () => {
  let mockLLMClient: ILLMClient;
  let generator: SummaryGenerator;

  beforeEach(() => {
    mockLLMClient = createMockLLMClient();
    generator = new SummaryGenerator(mockLLMClient);
  });

  describe('summarizeMessages', () => {
    it('åº”è¯¥ä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦', async () => {
      const messages: ModelMessage[] = [
        { role: 'user', content: 'Hello' },
        { role: 'assistant', content: 'Hi there!' },
      ];

      const summary = await generator.summarizeMessages(messages);
      
      expect(summary).toBe('Test summary');
      expect(mockLLMClient.chat).toHaveBeenCalledTimes(1);
    });

    it('åº”è¯¥æ ¼å¼åŒ–æ¶ˆæ¯ä¸ºæ–‡æœ¬', async () => {
      const messages: ModelMessage[] = [
        { role: 'user', content: 'What is 2+2?' },
        { role: 'assistant', content: 'The answer is 4' },
      ];

      await generator.summarizeMessages(messages);
      
      const callArgs = (mockLLMClient.chat as any).mock.calls[0];
      const prompt = callArgs[0][0].content;
      
      expect(prompt).toContain('User:');
      expect(prompt).toContain('Assistant:');
      expect(prompt).toContain('2+2');
    });

    it('åº”è¯¥å¤„ç†å·¥å…·è°ƒç”¨æ¶ˆæ¯', async () => {
      const messages: ModelMessage[] = [
        { role: 'user', content: 'Navigate to example.com' },
        {
          role: 'assistant',
          content: [
            {
              type: 'tool-call',
              toolCallId: 'call-1',
              toolName: 'browser_navigate',
              args: { url: 'https://example.com' },
            },
          ],
        },
        {
          role: 'tool',
          content: [
            {
              type: 'tool-result',
              toolCallId: 'call-1',
              toolName: 'browser_navigate',
              output: 'Navigation successful',
            },
          ],
        },
      ];

      await generator.summarizeMessages(messages);
      
      const callArgs = (mockLLMClient.chat as any).mock.calls[0];
      const prompt = callArgs[0][0].content;
      
      expect(prompt).toContain('browser_navigate');
      expect(prompt).toContain('Tool Result:');
    });

    it('åº”è¯¥ä½¿ç”¨ maxSteps: 1 é¿å…å·¥å…·è°ƒç”¨', async () => {
      const messages: ModelMessage[] = [
        { role: 'user', content: 'test' },
      ];

      await generator.summarizeMessages(messages);
      
      const callArgs = (mockLLMClient.chat as any).mock.calls[0];
      const options = callArgs[1];
      
      expect(options.maxSteps).toBe(1);
    });

    it('åº”è¯¥å¤„ç†ç©ºæ¶ˆæ¯åˆ—è¡¨', async () => {
      const summary = await generator.summarizeMessages([]);
      
      expect(summary).toBe('Test summary');
    });

    it('åº”è¯¥å¤„ç†å¤æ‚çš„æ¶ˆæ¯å†…å®¹', async () => {
      const messages: ModelMessage[] = [
        { role: 'user', content: 'Test' },
        {
          role: 'assistant',
          content: [
            { type: 'text', text: 'Let me help' },
            {
              type: 'tool-call',
              toolCallId: 'call-1',
              toolName: 'tool1',
              args: { key: 'value' },
            },
          ],
        },
      ];

      const summary = await generator.summarizeMessages(messages);
      
      expect(summary).toBe('Test summary');
      expect(mockLLMClient.chat).toHaveBeenCalled();
    });
  });

  describe('é…ç½®é€‰é¡¹', () => {
    it('åº”è¯¥ä½¿ç”¨è‡ªå®šä¹‰ maxWords', async () => {
      const customGenerator = new SummaryGenerator(mockLLMClient, {
        maxWords: 100,
      });

      const messages: ModelMessage[] = [
        { role: 'user', content: 'test' },
      ];

      await customGenerator.summarizeMessages(messages);
      
      const callArgs = (mockLLMClient.chat as any).mock.calls[0];
      const prompt = callArgs[0][0].content;
      
      expect(prompt).toContain('100 words');
    });

    it('åº”è¯¥æ”¯æŒä¸­æ–‡è¾“å‡º', async () => {
      const chineseGenerator = new SummaryGenerator(mockLLMClient, {
        language: 'chinese',
      });

      const messages: ModelMessage[] = [
        { role: 'user', content: 'æµ‹è¯•' },
      ];

      await chineseGenerator.summarizeMessages(messages);
      
      const callArgs = (mockLLMClient.chat as any).mock.calls[0];
      const prompt = callArgs[0][0].content;
      
      expect(prompt).toContain('in Chinese');
    });

    it('åº”è¯¥æ”¯æŒè‹±æ–‡è¾“å‡º', async () => {
      const englishGenerator = new SummaryGenerator(mockLLMClient, {
        language: 'english',
      });

      const messages: ModelMessage[] = [
        { role: 'user', content: 'test' },
      ];

      await englishGenerator.summarizeMessages(messages);
      
      const callArgs = (mockLLMClient.chat as any).mock.calls[0];
      const prompt = callArgs[0][0].content;
      
      expect(prompt).toContain('in English');
    });

    it('åº”è¯¥æ”¯æŒè‡ªåŠ¨è¯­è¨€æ£€æµ‹', async () => {
      const autoGenerator = new SummaryGenerator(mockLLMClient, {
        language: 'auto',
      });

      const messages: ModelMessage[] = [
        { role: 'user', content: 'test' },
      ];

      await autoGenerator.summarizeMessages(messages);
      
      const callArgs = (mockLLMClient.chat as any).mock.calls[0];
      const prompt = callArgs[0][0].content;
      
      // auto æ¨¡å¼ä¸åº”è¯¥åŒ…å«è¯­è¨€æŒ‡ä»¤
      expect(prompt).not.toContain('in Chinese');
      expect(prompt).not.toContain('in English');
    });

    it('åº”è¯¥æ”¯æŒä¸åŒçš„æ‘˜è¦ç­–ç•¥', async () => {
      const strategies = ['concise', 'balanced', 'detailed'] as const;
      
      for (const strategy of strategies) {
        const client = createMockLLMClient();
        const gen = new SummaryGenerator(client, { strategy });
        
        await gen.summarizeMessages([{ role: 'user', content: 'test' }]);
        
        const callArgs = (client.chat as any).mock.calls[0];
        const prompt = callArgs[0][0].content;
        
        // åº”è¯¥åŒ…å«ç­–ç•¥ç›¸å…³çš„è¯
        if (strategy === 'concise') {
          expect(prompt).toContain('brief');
        } else if (strategy === 'detailed') {
          expect(prompt).toContain('comprehensive');
        }
      }
    });

    it('åº”è¯¥æ”¯æŒè‡ªå®šä¹‰ prompt æ¨¡æ¿', async () => {
      const customTemplate = 'Custom template with {messages} and {maxWords} words {language}';
      const customGenerator = new SummaryGenerator(mockLLMClient, {
        promptTemplate: customTemplate,
        maxWords: 150,
        language: 'chinese',
      });

      const messages: ModelMessage[] = [
        { role: 'user', content: 'test' },
      ];

      await customGenerator.summarizeMessages(messages);
      
      const callArgs = (mockLLMClient.chat as any).mock.calls[0];
      const prompt = callArgs[0][0].content;
      
      expect(prompt).toContain('Custom template');
      expect(prompt).toContain('150');
      expect(prompt).toContain('in Chinese');
    });
  });

  describe('å¿«æ·å‡½æ•°', () => {
    it('summarizeMessages å‡½æ•°åº”è¯¥å·¥ä½œ', async () => {
      const messages: ModelMessage[] = [
        { role: 'user', content: 'test' },
      ];

      const summary = await summarizeMessages(messages, mockLLMClient);
      
      expect(summary).toBe('Test summary');
      expect(mockLLMClient.chat).toHaveBeenCalled();
    });
  });

  describe('é”™è¯¯å¤„ç†', () => {
    it('åº”è¯¥ä¼ æ’­ LLM é”™è¯¯', async () => {
      const errorClient: ILLMClient = {
        chat: vi.fn().mockRejectedValue(new Error('LLM error')),
        stream: vi.fn(),
      } as any;

      const errorGenerator = new SummaryGenerator(errorClient);
      
      await expect(
        errorGenerator.summarizeMessages([{ role: 'user', content: 'test' }])
      ).rejects.toThrow('LLM error');
    });
  });

  describe('è¾¹ç•Œæƒ…å†µ', () => {
    it('åº”è¯¥å¤„ç†æžé•¿çš„æ¶ˆæ¯', async () => {
      const longContent = 'a'.repeat(10000);
      const messages: ModelMessage[] = [
        { role: 'user', content: longContent },
      ];

      const summary = await generator.summarizeMessages(messages);
      
      expect(summary).toBe('Test summary');
    });

    it('åº”è¯¥å¤„ç†ç‰¹æ®Šå­—ç¬¦', async () => {
      const messages: ModelMessage[] = [
        { role: 'user', content: 'ç‰¹æ®Šå­—ç¬¦ !@#$%^&*()' },
        { role: 'assistant', content: 'Response with ä¸­æ–‡ and emoji ðŸŽ‰' },
      ];

      const summary = await generator.summarizeMessages(messages);
      
      expect(summary).toBe('Test summary');
    });

    it('åº”è¯¥å¤„ç†æœªå®šä¹‰çš„å†…å®¹éƒ¨åˆ†', async () => {
      const messages: ModelMessage[] = [
        {
          role: 'assistant',
          content: [
            { type: 'text', text: undefined as any },
          ],
        },
      ];

      const summary = await generator.summarizeMessages(messages);
      
      expect(summary).toBe('Test summary');
    });

    it('åº”è¯¥æˆªæ–­è¿‡é•¿çš„å·¥å…·ç»“æžœ', async () => {
      const longOutput = 'x'.repeat(200);
      const messages: ModelMessage[] = [
        {
          role: 'tool',
          content: [
            {
              type: 'tool-result',
              toolCallId: 'call-1',
              toolName: 'tool1',
              output: longOutput,
            },
          ],
        },
      ];

      await generator.summarizeMessages(messages);
      
      const callArgs = (mockLLMClient.chat as any).mock.calls[0];
      const prompt = callArgs[0][0].content;
      
      // åº”è¯¥è¢«æˆªæ–­
      expect(prompt).toContain('...');
    });
  });
});

